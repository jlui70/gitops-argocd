#!/bin/bash

# Script para destruir todos os recursos na ordem correta
# VersÃ£o: 5.0 - ArgoCD GitOps
# Data: 22 de Janeiro de 2026
# Stacks: 00-backend, 01-networking, 02-eks-cluster (com ArgoCD)
# Changelog v5.0: Adaptado para ArgoCD GitOps (deleta Application ArgoCD primeiro)

set -e  # Para em caso de erro

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘     ğŸ—‘ï¸  DESTRUINDO INFRAESTRUTURA EKS + ARGOCD - 3 STACKS      â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# PROJECT_ROOT deve apontar para o diretÃ³rio raiz do projeto (gitops-argocd/), nÃ£o scripts/
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# AWS Profile usado (ajuste se necessÃ¡rio)
AWS_PROFILE="devopsproject"

# FunÃ§Ã£o para destruir uma stack
destroy_stack() {
    local stack_name=$1
    local stack_path=$2
    
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "ğŸ—‘ï¸  Destruindo: $stack_name"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    
    cd "$PROJECT_ROOT/$stack_path"
    
    if [ -f "terraform.tfstate" ] || terraform state list &>/dev/null; then
        terraform destroy -auto-approve || {
            echo "âš ï¸  Erro ao destruir $stack_name, tentando remover state Ã³rfÃ£o..."
            terraform state list 2>/dev/null | while read resource; do
                terraform state rm "$resource" 2>/dev/null || true
            done
            echo "âœ… $stack_name limpo (recursos jÃ¡ removidos)"
        }
        echo "âœ… $stack_name destruÃ­do com sucesso!"
    else
        echo "âš ï¸  $stack_name: Nenhum recurso para destruir"
    fi
    
    echo ""
}

# IMPORTANTE: Primeiro deletar recursos Kubernetes que criam recursos AWS
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§¹ PASSO 0: Deletando ArgoCD Application (GitOps)"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Verificar se kubectl consegue acessar o cluster
if kubectl cluster-info &>/dev/null; then
    echo "  âœ… Cluster acessÃ­vel via kubectl"
    
    # Deletar Application ArgoCD (ArgoCD vai remover todos os recursos do Git)
    if kubectl get application ecommerce-app -n argocd &>/dev/null 2>&1; then
        echo "  ğŸ—‘ï¸  Deletando ArgoCD Application: ecommerce-app"
        kubectl delete application ecommerce-app -n argocd --timeout=120s 2>/dev/null || true
        echo "  â³ Aguardando ArgoCD remover recursos (ALB, Services, Pods)... (60s)"
        sleep 60
        echo "  âœ… Application ArgoCD deletada"
    else
        echo "  â„¹ï¸  Application ArgoCD nÃ£o encontrada (jÃ¡ deletada ou nunca criada)"
    fi
    
    # Verificar e deletar namespace ecommerce se ainda existir
    if kubectl get namespace ecommerce &>/dev/null 2>&1; then
        echo "  ğŸ—‘ï¸  Deletando namespace ecommerce (forÃ§ando se necessÃ¡rio)..."
        kubectl delete namespace ecommerce --timeout=90s 2>/dev/null || true
        echo "  â³ Aguardando finalizaÃ§Ã£o... (30s)"
        sleep 30
    fi
    
    echo "  âœ… Recursos GitOps removidos"
else
    echo "  âš ï¸  Cluster inaccessÃ­vel via kubectl (pode jÃ¡ ter sido destruÃ­do)"
    echo "  â„¹ï¸  Prosseguindo com destroy do Terraform"
fi
echo ""

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§¹ PASSO 1: Limpando recursos CI/CD (ECR + IAM)"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# Deletar ECR repositories (criados manualmente para CI/CD - se existirem)
echo "ğŸ—‘ï¸  Deletando ECR repositories (se existirem)..."
ECR_REPOS=(
    "ecommerce/ecommerce-ui"
    "ecommerce/product-catalog"
    "ecommerce/order-management"
    "ecommerce/product-inventory"
    "ecommerce/profile-management"
    "ecommerce/shipping-and-handling"
    "ecommerce/contact-support-team"
)

for repo in "${ECR_REPOS[@]}"; do
    if aws ecr describe-repositories --repository-names "$repo" --region us-east-1 --profile $AWS_PROFILE &>/dev/null; then
        echo "  ğŸ—‘ï¸  Deletando ECR repo: $repo"
        aws ecr delete-repository --repository-name "$repo" --region us-east-1 --force --profile $AWS_PROFILE 2>/dev/null && \
            echo "    âœ… $repo deletado" || \
            echo "    âš ï¸  Erro ao deletar $repo"
    fi
done

# Deletar IAM user github-actions-eks (se existir)
echo ""
echo "ğŸ—‘ï¸  Deletando IAM user github-actions-eks (se existir)..."
if aws iam get-user --user-name github-actions-eks --profile $AWS_PROFILE &>/dev/null; then
    # Delete access keys
    ACCESS_KEYS=$(aws iam list-access-keys --user-name github-actions-eks --profile $AWS_PROFILE --query 'AccessKeyMetadata[].AccessKeyId' --output text 2>/dev/null)
    for key in $ACCESS_KEYS; do
        echo "  â†’ Deletando access key: $key"
        aws iam delete-access-key --user-name github-actions-eks --access-key-id "$key" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    # Detach managed policies
    ATTACHED_POLICIES=$(aws iam list-attached-user-policies --user-name github-actions-eks --profile $AWS_PROFILE --query 'AttachedPolicies[].PolicyArn' --output text 2>/dev/null)
    for policy_arn in $ATTACHED_POLICIES; do
        echo "  â†’ Detaching policy: $(basename $policy_arn)"
        aws iam detach-user-policy --user-name github-actions-eks --policy-arn "$policy_arn" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    # Delete inline policies
    INLINE_POLICIES=$(aws iam list-user-policies --user-name github-actions-eks --profile $AWS_PROFILE --query 'PolicyNames' --output text 2>/dev/null)
    for policy_name in $INLINE_POLICIES; do
        echo "  â†’ Deletando inline policy: $policy_name"
        aws iam delete-user-policy --user-name github-actions-eks --policy-name "$policy_name" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    # Delete user
    aws iam delete-user --user-name github-actions-eks --profile $AWS_PROFILE 2>/dev/null && \
        echo "  âœ… IAM user github-actions-eks deletado" || \
        echo "  âš ï¸  Erro ao deletar IAM user"
else
    echo "  â„¹ï¸  IAM user github-actions-eks nÃ£o encontrado"
fi
echo ""

# Ordem correta de destruiÃ§Ã£o (REVERSA da criaÃ§Ã£o: 02 â†’ 00)
echo "ğŸ“‹ Ordem de destruiÃ§Ã£o: 02-eks-cluster â†’ 01-networking â†’ 00-backend"
echo ""

# Stack 02: Remover helm releases do state (ArgoCD + ALB Controller + External DNS)
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§¹ Stack 02: Limpando state de helm releases Ã³rfÃ£os..."
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
cd "$PROJECT_ROOT/02-eks-cluster"
terraform state rm helm_release.argocd 2>/dev/null && echo "  âœ… ArgoCD helm release removido do state" || echo "  â„¹ï¸  ArgoCD jÃ¡ removido ou nÃ£o existe"
terraform state rm helm_release.load_balancer_controller 2>/dev/null && echo "  âœ… ALB Controller helm release removido do state" || echo "  â„¹ï¸  ALB Controller jÃ¡ removido ou nÃ£o existe"
terraform state rm helm_release.external_dns 2>/dev/null && echo "  âœ… External DNS helm release removido do state" || echo "  â„¹ï¸  External DNS jÃ¡ removido ou nÃ£o existe"
terraform state rm helm_release.metrics_server 2>/dev/null && echo "  âœ… Metrics Server helm release removido do state" || echo "  â„¹ï¸  Metrics Server jÃ¡ removido ou nÃ£o existe"
echo ""

destroy_stack "Stack 02 - EKS Cluster" "02-eks-cluster"

# IMPORTANTE: Limpar IAM roles/policies Ã³rfÃ£s que o Terraform pode nÃ£o ter deletado

# Limpeza de recursos AWS Ã³rfÃ£os (quando Terraform state estÃ¡ vazio)
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§¹ Verificando e limpando recursos AWS Ã³rfÃ£os"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# 1. Deletar Load Balancers Ã³rfÃ£os (ArgoCD, ALB da aplicaÃ§Ã£o)
echo "  ğŸ” Procurando Load Balancers Ã³rfÃ£os..."
ORPHAN_ALBS=$(aws elbv2 describe-load-balancers \
    --profile $AWS_PROFILE \
    --query "LoadBalancers[?contains(LoadBalancerName, 'k8s-argocd') || contains(LoadBalancerName, 'k8s-ecommerc')].LoadBalancerArn" \
    --output text 2>/dev/null)

if [ -n "$ORPHAN_ALBS" ]; then
    echo "  ğŸ—‘ï¸  Deletando ALBs Ã³rfÃ£os:"
    for alb_arn in $ORPHAN_ALBS; do
        ALB_NAME=$(aws elbv2 describe-load-balancers --load-balancer-arns "$alb_arn" --profile $AWS_PROFILE --query 'LoadBalancers[0].LoadBalancerName' --output text)
        echo "    â†’ Deletando ALB: $ALB_NAME"
        aws elbv2 delete-load-balancer --load-balancer-arn "$alb_arn" --profile $AWS_PROFILE 2>/dev/null && \
            echo "      âœ… ALB deletado" || \
            echo "      âš ï¸  Falha ao deletar"
    done
    echo "  â³ Aguardando ALBs serem deletados (30s)..."
    sleep 30
else
    echo "  â„¹ï¸  Nenhum ALB Ã³rfÃ£o encontrado"
fi
echo ""

# 2. Deletar Target Groups Ã³rfÃ£os
echo "  ğŸ” Procurando Target Groups Ã³rfÃ£os..."
ORPHAN_TGS=$(aws elbv2 describe-target-groups \
    --profile $AWS_PROFILE \
    --query "TargetGroups[?contains(TargetGroupName, 'k8s-')].TargetGroupArn" \
    --output text 2>/dev/null)

if [ -n "$ORPHAN_TGS" ]; then
    echo "  ğŸ—‘ï¸  Deletando Target Groups Ã³rfÃ£os:"
    for tg_arn in $ORPHAN_TGS; do
        TG_NAME=$(aws elbv2 describe-target-groups --target-group-arns "$tg_arn" --profile $AWS_PROFILE --query 'TargetGroups[0].TargetGroupName' --output text)
        echo "    â†’ Deletando TG: $TG_NAME"
        aws elbv2 delete-target-group --target-group-arn "$tg_arn" --profile $AWS_PROFILE 2>/dev/null && \
            echo "      âœ… TG deletado" || \
            echo "      âš ï¸  Falha ao deletar"
    done
else
    echo "  â„¹ï¸  Nenhum Target Group Ã³rfÃ£o encontrado"
fi
echo ""

# 3. Deletar Security Groups Ã³rfÃ£os (exceto default)
echo "  ğŸ” Procurando Security Groups Ã³rfÃ£os..."
VPC_ID=$(aws ec2 describe-vpcs \
    --filters "Name=tag:Name,Values=eks-devopsproject-vpc" \
    --profile $AWS_PROFILE \
    --query 'Vpcs[0].VpcId' \
    --output text 2>/dev/null)

if [ "$VPC_ID" != "None" ] && [ -n "$VPC_ID" ]; then
    ORPHAN_SGS=$(aws ec2 describe-security-groups \
        --filters "Name=vpc-id,Values=$VPC_ID" \
        --profile $AWS_PROFILE \
        --query "SecurityGroups[?GroupName!='default'].GroupId" \
        --output text 2>/dev/null)
    
    if [ -n "$ORPHAN_SGS" ]; then
        echo "  ğŸ—‘ï¸  Deletando Security Groups Ã³rfÃ£os:"
        for sg_id in $ORPHAN_SGS; do
            SG_NAME=$(aws ec2 describe-security-groups --group-ids "$sg_id" --profile $AWS_PROFILE --query 'SecurityGroups[0].GroupName' --output text)
            echo "    â†’ Deletando SG: $SG_NAME ($sg_id)"
            
            # Remover regras primeiro
            aws ec2 revoke-security-group-ingress --group-id "$sg_id" --profile $AWS_PROFILE --source-group "$sg_id" 2>/dev/null || true
            aws ec2 revoke-security-group-egress --group-id "$sg_id" --profile $AWS_PROFILE --cidr 0.0.0.0/0 --protocol -1 2>/dev/null || true
            
            aws ec2 delete-security-group --group-id "$sg_id" --profile $AWS_PROFILE 2>/dev/null && \
                echo "      âœ… SG deletado" || \
                echo "      âš ï¸  Falha ao deletar (pode ter dependÃªncias)"
        done
    else
        echo "  â„¹ï¸  Nenhum Security Group Ã³rfÃ£o encontrado"
    fi
fi
echo ""
# Isso evita erro "EntityAlreadyExists" em reinstalaÃ§Ãµes
# VERSÃƒO DINÃ‚MICA v3.2: LÃª nomes reais do Terraform state (funciona mesmo se usuÃ¡rio alterar variables.tf)
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§¹ Limpando IAM Roles/Policies Ã³rfÃ£s (prevenÃ§Ã£o de conflitos)..."
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# FunÃ§Ã£o auxiliar para deletar role IAM (detach policies primeiro)
delete_iam_role() {
    local role_name=$1
    
    if [ -z "$role_name" ]; then
        return 0
    fi
    
    if aws iam get-role --role-name "$role_name" --profile $AWS_PROFILE &>/dev/null; then
        echo "  ğŸ—‘ï¸  Deletando role: $role_name"
        
        # Detach managed policies
        ATTACHED_POLICIES=$(aws iam list-attached-role-policies \
            --role-name "$role_name" \
            --profile $AWS_PROFILE \
            --query 'AttachedPolicies[].PolicyArn' \
            --output text 2>/dev/null || echo "")
        
        for policy_arn in $ATTACHED_POLICIES; do
            aws iam detach-role-policy \
                --role-name "$role_name" \
                --policy-arn "$policy_arn" \
                --profile $AWS_PROFILE 2>/dev/null || true
        done
        
        # Delete inline policies
        INLINE_POLICIES=$(aws iam list-role-policies \
            --role-name "$role_name" \
            --profile $AWS_PROFILE \
            --query 'PolicyNames' \
            --output text 2>/dev/null || echo "")
        
        for policy_name in $INLINE_POLICIES; do
            aws iam delete-role-policy \
                --role-name "$role_name" \
                --policy-name "$policy_name" \
                --profile $AWS_PROFILE 2>/dev/null || true
        done
        
        # Remove from instance profiles AND delete the profiles
        INSTANCE_PROFILES=$(aws iam list-instance-profiles-for-role \
            --role-name "$role_name" \
            --profile $AWS_PROFILE \
            --query 'InstanceProfiles[].InstanceProfileName' \
            --output text 2>/dev/null || echo "")
        
        for profile_name in $INSTANCE_PROFILES; do
            echo "    â†’ Removendo role do instance profile: $profile_name"
            aws iam remove-role-from-instance-profile \
                --instance-profile-name "$profile_name" \
                --role-name "$role_name" \
                --profile $AWS_PROFILE 2>/dev/null || true
            
            # Deletar o instance profile (Ã³rfÃ£o criado pelo EKS)
            echo "    â†’ Deletando instance profile Ã³rfÃ£o: $profile_name"
            aws iam delete-instance-profile \
                --instance-profile-name "$profile_name" \
                --profile $AWS_PROFILE 2>/dev/null || true
        done
        
        # Delete role
        aws iam delete-role --role-name "$role_name" --profile $AWS_PROFILE 2>/dev/null && \
            echo "    âœ… Role $role_name deletada" || \
            echo "    âš ï¸  Role $role_name nÃ£o pÃ´de ser deletada"
    fi
}

# FunÃ§Ã£o auxiliar para extrair nome de role do Terraform state
get_role_name_from_state() {
    local stack_path=$1
    local resource_address=$2
    
    # Verificar se o diretÃ³rio existe
    [ ! -d "$PROJECT_ROOT/$stack_path" ] && return
    
    cd "$PROJECT_ROOT/$stack_path"
    
    # Tentar obter nome da role do state (com timeout de 5s)
    local role_name=$(timeout 5 terraform state show "$resource_address" 2>/dev/null | grep -E "^\s+name\s+=" | head -1 | awk -F'"' '{print $2}')
    
    echo "$role_name"
}

# FunÃ§Ã£o auxiliar para extrair nome de policy do Terraform state
get_policy_name_from_state() {
    local stack_path=$1
    local resource_address=$2
    
    # Verificar se o diretÃ³rio existe
    [ ! -d "$PROJECT_ROOT/$stack_path" ] && return
    
    cd "$PROJECT_ROOT/$stack_path"
    
    # Tentar obter nome da policy do state (com timeout de 5s)
    local policy_name=$(timeout 5 terraform state show "$resource_address" 2>/dev/null | grep -E "^\s+name\s+=" | head -1 | awk -F'"' '{print $2}')
    
    echo "$policy_name"
}

# Obter account ID dinamicamente
ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text --profile $AWS_PROFILE 2>/dev/null || echo "")

if [ -z "$ACCOUNT_ID" ]; then
    echo "  âš ï¸  NÃ£o foi possÃ­vel obter Account ID, pulando limpeza de IAM"
else
    echo "  ğŸ“Š Account ID: $ACCOUNT_ID"
    echo "  ğŸ” Lendo nomes reais das roles do Terraform state..."
    echo ""
    
    # ======================================================================
    # STACK 02 - EKS CLUSTER ROLES (lendo dinamicamente do state)
    # ======================================================================
    echo "  ğŸ—‚ï¸  Stack 02 - EKS Cluster"
    
    ROLE_CSI=$(get_role_name_from_state "02-eks-cluster" "aws_iam_role.container_storage_interface")
    ROLE_ALB=$(get_role_name_from_state "02-eks-cluster" "aws_iam_role.load_balancer_controller")
    ROLE_NODE=$(get_role_name_from_state "02-eks-cluster" "aws_iam_role.eks_cluster_node_group")
    ROLE_CLUSTER=$(get_role_name_from_state "02-eks-cluster" "aws_iam_role.eks_cluster")
    ROLE_DNS=$(get_role_name_from_state "02-eks-cluster" "aws_iam_role.external_dns")
    
    POLICY_ALB=$(get_policy_name_from_state "02-eks-cluster" "aws_iam_policy.load_balancer_controller")
    
    [ -n "$ROLE_CSI" ] && delete_iam_role "$ROLE_CSI" || delete_iam_role "AmazonEKS_EFS_CSI_DriverRole"
    [ -n "$ROLE_ALB" ] && delete_iam_role "$ROLE_ALB" || delete_iam_role "aws-load-balancer-controller"
    [ -n "$ROLE_NODE" ] && delete_iam_role "$ROLE_NODE" || delete_iam_role "eks-devopsproject-node-group-role"
    [ -n "$ROLE_CLUSTER" ] && delete_iam_role "$ROLE_CLUSTER" || delete_iam_role "eks-devopsproject-cluster-role"
    [ -n "$ROLE_DNS" ] && delete_iam_role "$ROLE_DNS" || delete_iam_role "external-dns-irsa-role"
    
    # Deletar policy ALB Controller
    if [ -n "$POLICY_ALB" ]; then
        POLICY_ARN="arn:aws:iam::${ACCOUNT_ID}:policy/${POLICY_ALB}"
    else
        POLICY_ARN="arn:aws:iam::${ACCOUNT_ID}:policy/AWSLoadBalancerControllerIAMPolicy"
    fi
    
    if aws iam get-policy --policy-arn "$POLICY_ARN" --profile $AWS_PROFILE &>/dev/null; then
        echo "  ğŸ—‘ï¸  Deletando policy: $(basename $POLICY_ARN)"
        aws iam delete-policy --policy-arn "$POLICY_ARN" --profile $AWS_PROFILE 2>/dev/null && \
            echo "    âœ… Policy deletada" || \
            echo "    âš ï¸  Policy nÃ£o pÃ´de ser deletada (pode estar attached)"
    fi
    echo ""
    
    echo "  âœ… Limpeza de IAM concluÃ­da (modo dinÃ¢mico v3.2)"
fi
echo ""

# Limpeza de ENIs Ã³rfÃ£as (ALB) antes de destruir VPC
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§¹ Limpando ENIs Ã³rfÃ£as (ALB) antes de destruir VPC"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

# Obter VPC ID do Terraform state
cd "$PROJECT_ROOT/01-networking"
VPC_ID=$(terraform state show aws_vpc.this 2>/dev/null | grep -E "^\s+id\s+=" | awk -F'"' '{print $2}')

if [ -n "$VPC_ID" ]; then
    echo "  ğŸ“Š VPC ID: $VPC_ID"
    echo "  ğŸ” Procurando ENIs Ã³rfÃ£as..."
    
    # Listar ENIs na VPC que:
    # 1. EstÃ£o disponÃ­veis (nÃ£o attached) OU
    # 2. Foram criadas pelo ELB (ALB Controller)
    ORPHAN_ENIS=$(aws ec2 describe-network-interfaces \
        --filters "Name=vpc-id,Values=$VPC_ID" \
        --profile $AWS_PROFILE \
        --query 'NetworkInterfaces[?Status==`available` || contains(Description, `ELB`) || contains(RequesterId, `amazon-elb`)].NetworkInterfaceId' \
        --output text 2>/dev/null)
    
    if [ -n "$ORPHAN_ENIS" ]; then
        echo "  ğŸ—‘ï¸  Deletando ENIs Ã³rfÃ£as:"
        for eni_id in $ORPHAN_ENIS; do
            echo "    â†’ Deletando ENI: $eni_id"
            aws ec2 delete-network-interface \
                --network-interface-id "$eni_id" \
                --profile $AWS_PROFILE 2>/dev/null && \
                echo "      âœ… ENI deletada" || \
                echo "      âš ï¸  Falha ao deletar (pode estar em uso)"
        done
        echo "  â³ Aguardando propagaÃ§Ã£o (10s)..."
        sleep 10
    else
        echo "  â„¹ï¸  Nenhuma ENI Ã³rfÃ£ encontrada"
    fi
else
    echo "  âš ï¸  VPC ID nÃ£o encontrado no state (VPC jÃ¡ foi destruÃ­da?)"
fi
echo ""
destroy_stack "Stack 01 - Networking (VPC)" "01-networking"

# Backend por Ãºltimo
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ—‘ï¸  Destruindo: Stack 00 - Backend (S3 + DynamoDB)"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "â„¹ï¸  Backend serÃ¡ destruÃ­do automaticamente (necessÃ¡rio para rebuild limpo)"
echo ""

cd "$PROJECT_ROOT/00-backend"

# Obter nome do bucket do terraform
BUCKET_NAME=$(terraform output -raw s3_bucket_name 2>/dev/null)

if [ -z "$BUCKET_NAME" ]; then
    echo "âš ï¸  NÃ£o foi possÃ­vel obter nome do bucket. Tentando detectar..."
    ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text 2>/dev/null)
    BUCKET_NAME="eks-devopsproject-state-files-${ACCOUNT_ID}"
    echo "  â†’ Bucket detectado: $BUCKET_NAME"
fi

# Limpeza manual de VPC Ã³rfÃ£ (se Terraform falhou)
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸ§¹ Limpeza manual de VPC Ã³rfÃ£ (se existir)"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

VPC_ID=$(aws ec2 describe-vpcs \
    --filters "Name=tag:Name,Values=eks-devopsproject-vpc" \
    --profile $AWS_PROFILE \
    --query 'Vpcs[0].VpcId' \
    --output text 2>/dev/null)

if [ "$VPC_ID" != "None" ] && [ -n "$VPC_ID" ]; then
    echo "  ğŸ“Š VPC Ã³rfÃ£ encontrada: $VPC_ID"
    echo "  ğŸ—‘ï¸  Deletando recursos da VPC manualmente..."
    
    # 1. Deletar NAT Gateways
    echo "    â†’ Deletando NAT Gateways..."
    NAT_GWS=$(aws ec2 describe-nat-gateways \
        --filter "Name=vpc-id,Values=$VPC_ID" "Name=state,Values=available" \
        --profile $AWS_PROFILE \
        --query 'NatGateways[].NatGatewayId' \
        --output text 2>/dev/null)
    
    for nat_id in $NAT_GWS; do
        echo "      â†’ Deletando NAT Gateway: $nat_id"
        aws ec2 delete-nat-gateway --nat-gateway-id "$nat_id" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    if [ -n "$NAT_GWS" ]; then
        echo "      â³ Aguardando NAT Gateways serem deletados (60s)..."
        sleep 60
    fi
    
    # 2. Liberar e deletar Elastic IPs
    echo "    â†’ Deletando Elastic IPs..."
    EIPS=$(aws ec2 describe-addresses \
        --filters "Name=domain,Values=vpc" \
        --profile $AWS_PROFILE \
        --query 'Addresses[?contains(Tags[?Key==`Name`].Value, `devopsproject`) || AssociationId==null].AllocationId' \
        --output text 2>/dev/null)
    
    for eip_id in $EIPS; do
        echo "      â†’ Liberando EIP: $eip_id"
        aws ec2 release-address --allocation-id "$eip_id" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    # 3. Deletar ENIs restantes
    echo "    â†’ Deletando ENIs restantes..."
    ENIS=$(aws ec2 describe-network-interfaces \
        --filters "Name=vpc-id,Values=$VPC_ID" \
        --profile $AWS_PROFILE \
        --query 'NetworkInterfaces[].NetworkInterfaceId' \
        --output text 2>/dev/null)
    
    for eni_id in $ENIS; do
        echo "      â†’ Deletando ENI: $eni_id"
        aws ec2 delete-network-interface --network-interface-id "$eni_id" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    sleep 10
    
    # 4. Deletar Internet Gateway
    echo "    â†’ Deletando Internet Gateway..."
    IGW_ID=$(aws ec2 describe-internet-gateways \
        --filters "Name=attachment.vpc-id,Values=$VPC_ID" \
        --profile $AWS_PROFILE \
        --query 'InternetGateways[0].InternetGatewayId' \
        --output text 2>/dev/null)
    
    if [ "$IGW_ID" != "None" ] && [ -n "$IGW_ID" ]; then
        echo "      â†’ Detachando IGW: $IGW_ID"
        aws ec2 detach-internet-gateway --internet-gateway-id "$IGW_ID" --vpc-id "$VPC_ID" --profile $AWS_PROFILE 2>/dev/null || true
        echo "      â†’ Deletando IGW: $IGW_ID"
        aws ec2 delete-internet-gateway --internet-gateway-id "$IGW_ID" --profile $AWS_PROFILE 2>/dev/null || true
    fi
    
    # 5. Deletar Subnets
    echo "    â†’ Deletando Subnets..."
    SUBNETS=$(aws ec2 describe-subnets \
        --filters "Name=vpc-id,Values=$VPC_ID" \
        --profile $AWS_PROFILE \
        --query 'Subnets[].SubnetId' \
        --output text 2>/dev/null)
    
    for subnet_id in $SUBNETS; do
        echo "      â†’ Deletando Subnet: $subnet_id"
        aws ec2 delete-subnet --subnet-id "$subnet_id" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    # 6. Deletar Route Tables (exceto main)
    echo "    â†’ Deletando Route Tables..."
    ROUTE_TABLES=$(aws ec2 describe-route-tables \
        --filters "Name=vpc-id,Values=$VPC_ID" \
        --profile $AWS_PROFILE \
        --query 'RouteTables[?Associations[0].Main!=`true`].RouteTableId' \
        --output text 2>/dev/null)
    
    for rt_id in $ROUTE_TABLES; do
        echo "      â†’ Deletando Route Table: $rt_id"
        aws ec2 delete-route-table --route-table-id "$rt_id" --profile $AWS_PROFILE 2>/dev/null || true
    done
    
    # 7. Deletar VPC
    echo "    â†’ Deletando VPC: $VPC_ID"
    aws ec2 delete-vpc --vpc-id "$VPC_ID" --profile $AWS_PROFILE 2>/dev/null && \
        echo "      âœ… VPC deletada com sucesso!" || \
        echo "      âš ï¸  Falha ao deletar VPC (pode ter dependÃªncias restantes)"
else
    echo "  â„¹ï¸  Nenhuma VPC Ã³rfÃ£ encontrada"
fi
echo ""

echo "ğŸ§¹ Esvaziando bucket S3: $BUCKET_NAME"

# Verificar se bucket existe antes de tentar esvaziar
if aws s3 ls "s3://$BUCKET_NAME" --profile $AWS_PROFILE &>/dev/null; then
    echo "  â†’ Removendo todos os objetos e versÃµes do bucket..."
    
    # MÃ©todo 1: Usar aws s3 rm com --recursive (mais simples e confiÃ¡vel)
    aws s3 rm "s3://$BUCKET_NAME" --recursive --profile $AWS_PROFILE 2>/dev/null || true
    
    # MÃ©todo 2: Deletar versÃµes antigas (versionamento habilitado)
    echo "  â†’ Verificando versÃµes antigas..."
    VERSIONS=$(aws s3api list-object-versions \
        --bucket "$BUCKET_NAME" \
        --profile $AWS_PROFILE \
        --output json \
        --query '{Objects: Versions[].{Key:Key,VersionId:VersionId}}' 2>/dev/null)
    
    if [ "$VERSIONS" != "null" ] && [ "$VERSIONS" != "" ] && [ "$VERSIONS" != "{}" ]; then
        echo "  â†’ Removendo versÃµes de objetos..."
        aws s3api delete-objects \
            --bucket "$BUCKET_NAME" \
            --profile $AWS_PROFILE \
            --delete "$VERSIONS" 2>/dev/null || true
    fi
    
    # MÃ©todo 3: Deletar delete markers
    echo "  â†’ Verificando delete markers..."
    MARKERS=$(aws s3api list-object-versions \
        --bucket "$BUCKET_NAME" \
        --profile $AWS_PROFILE \
        --output json \
        --query '{Objects: DeleteMarkers[].{Key:Key,VersionId:VersionId}}' 2>/dev/null)
    
    if [ "$MARKERS" != "null" ] && [ "$MARKERS" != "" ] && [ "$MARKERS" != "{}" ]; then
        echo "  â†’ Removendo delete markers..."
        aws s3api delete-objects \
            --bucket "$BUCKET_NAME" \
            --profile $AWS_PROFILE \
        --delete "$MARKERS" 2>/dev/null || true
fi

echo "  âœ… Bucket esvaziado completamente"
else
echo "  â„¹ï¸  Bucket nÃ£o encontrado ou jÃ¡ foi deletado"
fi
echo ""

# Agora destruir o backend (com force_destroy = true, mesmo se houver objetos restantes)
terraform destroy -auto-approve
echo "âœ… Stack 00 - Backend destruÃ­do"
echo ""

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘              âœ… DESTRUIÃ‡ÃƒO COMPLETA!                            â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“Š Recursos destruÃ­dos:"
echo "  âœ… ECR Repositories (7 repos)"
echo "  âœ… IAM user github-actions-eks"
echo "  âœ… Namespace ecommerce + ALB (via kubectl)"
echo "  âœ… Namespace sample-app (se existia)"
echo "  âœ… Stack 02: EKS Cluster + Node Group + ALB Controller + External DNS"
echo "  âœ… Stack 01: VPC + Subnets + NAT Gateways + EIPs"
echo "  âœ… Stack 00: Backend (S3 + DynamoDB)"
echo ""
echo "ğŸ’° Custos AWS agora: ~$0/mÃªs"
echo ""
echo "ğŸ”„ Para recriar tudo: ./scripts/rebuild-all.sh"
echo ""
